# -*- coding: utf-8 -*-
"""cw1 sentiment analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V0wNkUo-u9Bsj8QwsRoNViLbLHf7kgUF
"""

!pip install --upgrade --force-reinstall nltk
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')

import nltk
nltk.data.find('tokenizers/punkt')
print("NLTK punkt is installed correctly!")

!pip install --upgrade --force-reinstall nltk
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
nltk.download('punkt_tab')

# Necessary imports
import string
import nltk
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier  # Added KNN
from nltk.corpus import stopwords

# Ensure NLTK resources are installed
nltk.download('punkt')
nltk.download('stopwords')

# Define stopwords and punctuation
STOP_WORDS = set(stopwords.words('english'))
PUNCTUATION = set(string.punctuation)

# Load and preprocess data
data = pd.read_csv('/content/SemEval2017-task4-dev.subtask-A.english.INPUT.txt', sep='\t')
texts = data.iloc[:, 2].values  # Extract text column
labels = data.iloc[:, 1].values  # Extract sentiment column

# Mapping sentiment labels to numeric values
label_mapping = {'positive': 1, 'neutral': 0, 'negative': -1}
numeric_labels = np.array([label_mapping[label] for label in labels])

# Preprocessing function for text
def preprocess_text(text):
    tokens = nltk.word_tokenize(text)
    cleaned_tokens = []
    skip_next = False
    for tok in tokens:
        tok = tok.lower()
        if skip_next:
            skip_next = False
            continue
        if tok == '@':  # Skip usernames
            skip_next = True
            continue
        if 'http' in tok or '//t.co/' in tok:  # Remove links
            continue
        if tok in STOP_WORDS or tok in PUNCTUATION or tok in ['..', '...', "'s"]:  # Stopwords/punctuation
            continue
        cleaned_tokens.append(tok)
    return " ".join(cleaned_tokens)

# Preprocess all texts
processed_texts = [preprocess_text(t) for t in texts]

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(stop_words='english')
vectorized_data = vectorizer.fit_transform(processed_texts)

# Split data into training and test sets (80/20 split)
split_index = int(len(texts) * 0.8)
x_train, x_test = vectorized_data[:split_index].toarray(), vectorized_data[split_index:].toarray()
y_train, y_test = numeric_labels[:split_index], numeric_labels[split_index:]

# Define models
models = {
    "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000),
    "Naive Bayes": MultinomialNB(),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5)  # Added KNN
}

# Define metrics
def calculate_metrics(y_true, y_pred, sentiment):
    precision = np.sum((y_pred == sentiment) & (y_true == sentiment)) / \
                np.sum(y_pred == sentiment) if np.sum(y_pred == sentiment) > 0 else 0
    recall = np.sum((y_pred == sentiment) & (y_true == sentiment)) / \
             np.sum(y_true == sentiment) if np.sum(y_true == sentiment) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    return precision, recall, f1

def calculate_accuracy(y_true, y_pred):
    return np.mean(y_true == y_pred)

!pip install --upgrade --force-reinstall xgboost
from xgboost import XGBClassifier

# Add XGBoost to the list of models, and adjust the target variable for training:
models["XGBoost"] = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)

# Train and evaluate XGBoost alongside other models
results = {} # Reinitialize results for all models
for model_name, model in models.items():
    # Adjust y_train for XGBoost to have labels 0, 1, 2
    if model_name == "XGBoost":
        adjusted_y_train = y_train + 1  # Shift labels by 1
        model.fit(x_train, adjusted_y_train)
    else:
        model.fit(x_train, y_train)

    predictions = model.predict(x_test)

    # Adjust predictions back to original labels for XGBoost
    if model_name == "XGBoost":
        predictions = predictions - 1  # Shift predictions back by 1

    accuracy = calculate_accuracy(y_test, predictions)

    metrics = {}
    for sentiment, sentiment_label in [("Negative", -1), ("Neutral", 0), ("Positive", 1)]:
        precision, recall, f1 = calculate_metrics(y_test, predictions, sentiment_label)
        metrics[sentiment] = {'Precision': precision, 'Recall': recall, 'F1-Score': f1}

    macro_precision = np.mean([metrics[s]['Precision'] for s in metrics])
    macro_recall = np.mean([metrics[s]['Recall'] for s in metrics])
    macro_f1 = np.mean([metrics[s]['F1-Score'] for s in metrics])

    results[model_name] = {
        'Accuracy': accuracy,
        'Metrics': metrics,
        'Macro Precision': macro_precision,
        'Macro Recall': macro_recall,
        'Macro F1-Score': macro_f1
    }

# Display results
for model_name, result in results.items():
    print(f"\nResults for {model_name}:")
    print(f" Accuracy: {result['Accuracy']:.4f}")
    for sentiment, scores in result['Metrics'].items():
        print(f" {sentiment} - Precision: {scores['Precision']:.4f}, Recall: {scores['Recall']:.4f}, F1-Score: {scores['F1-Score']:.4f}")
    print(f" Macro Precision: {result['Macro Precision']:.4f}, Macro Recall: {result['Macro Recall']:.4f}, Macro F1-Score: {result['Macro F1-Score']:.4f}")

# Save results to CSV
output = "Model, Sentiment, Precision, Recall, F1-Score\n"
for model_name, result in results.items():
    for sentiment, scores in result['Metrics'].items():
        output += f"{model_name}, {sentiment}, {scores['Precision']:.4f}, {scores['Recall']:.4f}, {scores['F1-Score']:.4f}\n"
    output += f"{model_name}, Macro Average, {result['Macro Precision']:.4f}, {result['Macro Recall']:.4f}, {result['Macro F1-Score']:.4f}\n"

with open('all_models_metrics.csv', 'w') as file:
    file.write(output)

print("\nResults saved to 'all_models_metrics.csv'.")